\section{Numerical Experiments}\label{sec:exp}

The \AlgName{} algorithm was compared against a base-line co-kriging algorithm and an implementation of the \motos{}~\cite{xu2016mo2tos} on two test problem suites. All codes were implemented and executed in MATLAB version R2020b, with kriging and co-kriging models constructed using the ooDACE toolbox~\cite{oodace} with default parameters.
All algorithms were run 30 times on each problem instance for the equivalent of 2000 LF evaluations~($=400$ HF evaluations), recording the best objective value, the mean and standard deviation of the resulting solutions produced by each trial. To establish statistical significance of the results, a pairwise comparison was made using the Mann-Whitney-Wilcoxon (MWW) test~\cite{mann1947test}, with the number of ``wins'', ``losses'' and ``draws'' recorded for each algorithm. For each pairwise comparison, let $\delta^p_{ab} = \mu^p_a - \mu^p_b$, with $\mu^p_i$ being the mean objective value for algorithm $i$ on problem instance $p$ over all trials. If the $p$-value for MWW is less than 0.05 and $|\delta^p_{ab}| > 10^{-5}$, algorithm $a$ is said to have ``won'' when $\delta^p_{ab} < 0$, ``lost'' when $\delta^p_{ab} > 0$ and ``drawn'' if both initial conditions are not met.

\subsection{Test problems}
The experiments were run on a collection of multi-fidelity test functions divided into two different test suites. The first suite (suite $A$) is a selection of problem instances taken from Lv~et~al.~\cite{lv2021multi}. Problems $f10$ to $f17$ were chosen from this suite as they contain between three and eight decision variables, determined as a representative range of easy to difficult problems. The explicit definitions for both the LF and HF functions are provided in the Appendix~\ref{app:testfuncs}\hemant{Supplementary (see note at the end of subsection)}.

The second set of problem instances (suite $B$) is generated using the well-known test functions of Griewank~\cite{griewank1981generalized} and Michalewicz~\cite{michalewicz2013genetic}. Each problem was instantiated with versions for three, five and eight decision variables. This matches the range of the first test suite, and also allows the performance of the algorithms to be judged across different sized problems in a more controlled environment. Since these test problems are not naturally multi-fidelity optimisation problems, low-fidelity functions are constructed by applying the methods described in~\cite{wang2017generic}. Two different error functions were tested for each instance, modelling two types of fidelity error: resolution and stochastic. An appropriate fidelity level $\phi$ for each problem was chosen by computing the square of the Pearson correlation coefficient $r^2$ for different fidelity values and selecting a value for $\phi$ such that $r^2$ was between 0.65 and 0.85, to be commensurate with the first test suite.

See Tables~\ref{tab:funcs} and~\ref{tab:errfuncs} in the Appendix~\ref{app:testfuncs} for test functions and error function equations, respectively.\hemant{Please move the appendix to a separate file called Supplementary and it as such. Otherwise IEEE system will (likely) return the paper during admin processing due to the manuscript pdf being over 15 pages.}

\subsection{\AlgName{} parameters}
The \AlgName{} algorithm is a modular framework where various search and modeling methods can be implemented. Its components can be divided into two categories: \AlgName{} specific components, which are intrinsic to its operation and whose parameters are also intrinsic; and, generic components, such as global search techniques and modelling methods which can be substituted by other similar techniques, which come with their own set of parameters. The \AlgName{} specific parameters are discussed in Section~\ref{sec:method}.

To reduce the number of arbitrary parameters, initial population sizes are defined as a function of the problem size. The HF population has a size of $6D$, as this is the smallest number of HF solutions that can be used to generate a co-kriging model for all the instances, with the LF population being $18D$, which was chosen using sensitivity analysis as the smallest value which still produces good solutions across the set of instances.

The maximum size that the LF archive can reach before it must be truncated is set to 400. This was chosen because values much higher than this significantly slowed the procedure down while yielding minimal-to-no improvement. 

In the $LocalOCBA$ procedure, the total number of solutions to be sampled, $\Delta_1$, is set to 25 and the number of samples per statistics update, $\Delta_2$, is set to 5. These were chosen to provide a good balance between speed and efficiency. The clustering method used to partition the solutions is $k$-means clustering, with the value for $k$ being chosen using the so-called \emph{elbow method}~\cite{leonard1990finding}.

Differential evolution (DE)~\cite{storn1997differential} was used to globally search the updated co-kriging model. The ``classical'' DE (DE/rand/1/bin) was run over 30 generations with a crossover rate of 0.9, a mutation factor of 0.5 and a population size of 100.

% The kriging models used are from the ooDACE toolbox~\cite{oodace}, with the default parameters.

\subsection{Baseline co-kriging algorithm}
Co-kriging is a popular approach used in solving multi-fidelity optimization problems. The outer-loop of the \AlgName{} algorithm functions by iteratively updating a co-kriging model using data from a modified version of the OCBA procedure. In order to demonstrate the effectiveness of this new technique, the performance of \AlgName{} is compared against the base-line co-kriging algorithm given in Algorithm~\ref{alg:co-kriging}.


\begin{algorithm}[h!] 
\caption{Base-line co-kriging procedure}
\label{alg:co-kriging}
\algsetup{linenosize=\footnotesize}
{\footnotesize
\begin{algorithmic}[1]
\REQUIRE{$\mathcal{I}$, problem instance; $N_{L}$, max size of LF pop; $T$, maximum number of evaluations; $\Delta$, new LF per iteration.}
\ENSURE{Best solution found $\V{x}^\beta$.}
\STATE{$X_v \ot LHS(\mathcal{I}),\ \forall v \in \{L,H\}$} \COMMENT{Generate initial populations}
\STATE{$A_v,t \ot f_v(X_v,0),\ \forall v \in \{L,H\}$} \COMMENT{Evaluate initial populations}
\STATE{$\V{x}^\beta \ot \emptyset$} \COMMENT{Initialize $x_\beta$} 
\WHILE{$t < T$}
  \STATE{$A_L \ot A_L \cup LHS(\Delta)$} \COMMENT{Add $\Delta$ new solutions to LF archive}
  \IF{$|A_L| > N_L$}
    \STATE{$A_L \ot Truncate(A_L,N_L)$} \COMMENT{Control population size}
  \ENDIF
  \STATE{$M_C \ot CoKrige(A_L,A_H)$} \COMMENT{Update co-kriging model}
  \STATE{$\V{x} \ot GlobalSearch(M_C)$} \COMMENT{Globally search co-kriging model}
  \STATE{$\V{\alpha},t \ot f_H(\V{x},t)$} \COMMENT{Evaluate and update total cost}
  \STATE{$A_H \ot A_H \cup \{\V{\alpha}\}$} \COMMENT{Add $\V{\alpha}$ to high-fidelity archive}
  \STATE{$\V{x}^\beta \ot \min(f_H(\V{x}^\beta),f_H(\V{x}))$} \COMMENT{Update best solution}
\ENDWHILE
\end{algorithmic}
}
\end{algorithm}

The functions here have the same definitions as in Algorithm~\ref{alg:main-alg}. This procedure iteratively updates a co-kriging model by randomly sampling the low-fidelity data using a Latin hypercube sampling (LHS) technique; however, the global search method is the same.

\subsection{\motos{} algorithm}

The second method used for comparison with \AlgName{} is the \motos{} algorithm described in Section~\ref{sec:back}. The source code for this algorithm could not be retrieved online, so an implementation in MATLAB based on the description in~\cite{xu2016mo2tos} was made, the pseudo-code for which is given in Algorithm~\ref{alg:mo2tos}.
\begin{algorithm}[h!] 
\caption{\motos{} procedure}
\label{alg:mo2tos}
\algsetup{linenosize=\footnotesize}
{\footnotesize
\begin{algorithmic}[1]
\REQUIRE{$\mathcal{I}$, problem instance; $T$, max LF equivalent evals; $n_0$, initial HF evals; $\rho_m$, HF eval proportion; $q$, number of partitions; $\Delta$, HF evals per statistics update.}
\ENSURE{Best solution found $\V{x}^\beta$.}
\STATE{$X_L \ot LHS(\mathcal{I},N_{e_{max}},\rho_m)$} \COMMENT{Generate initial population}
\STATE{$A_L,t \ot f_L(X_L,0)$} \COMMENT{Evaluate initial LF population}
\STATE{$G \ot Partition(A_L,q)$} \COMMENT{Partition solutions into $k$ groups}
\STATE{$D_i \ot randSelect(G_i,n_0),\ \forall i \in [q]$} \COMMENT{Select initial HF candidates}
\STATE{$S_i,t \ot f_L(D_i,t),\ \forall i \in [q]$} \COMMENT{Evaluate selected solutions}
\STATE{$G_i \ot G_i \setminus D_i,\ \forall i \in [q]$} \COMMENT{Selection without replacement}
\WHILE{$t < T$}
  \STATE{$\hat{\mu}_i,\hat{\sigma}_i \ot$ sample statistics for $S_i$, $\forall i \in [q]$}
  \STATE{$R \ot GetRatios(\V{\hat{\mu}},\V{\hat{\sigma}})$} \COMMENT{compute allocation ratios}
  \STATE{$D \ot Allocate(R,S,G) : \displaystyle\sum_{i \in [q]}|D_i| = \Delta$} \COMMENT{Allocate solutions}
  \STATE{$D_i,t \ot f_L(D_i,t),\ \forall i \in [q]$} \COMMENT{Evaluate allocated solutions}
  \STATE{$S_i \ot S_i \cup D_i,\ \forall i \in [q]$} \COMMENT{Add to selected solutions}
  \STATE{$G_i \ot G_i \setminus D_i,\ \forall i \in [q]$} \COMMENT{Selection without replacement}
\ENDWHILE
\STATE{$\V{x}^\beta \ot \min\left(\displaystyle\bigcup_{i \in [q]} S_i\right)$} \COMMENT{Find best selected solution}
\end{algorithmic}
}
\end{algorithm}

Here, most of the subroutines are the same as those previously discussed in Sections~\ref{sec:back} and~\ref{sec:method}. The total computing budget, $T$, must be divided between the initial LF evaluations and the subsequent HF ones, with the proportion of the total computing budget allocated to the HF evaluations given by the parameter $\rho_m$. In~\cite{xu2016mo2tos}, no guidelines were provided for setting this parameter; however sensitivity analysis experiments showed that a value of around 0.25 for $\rho_m$ provided the best results for the given problem instances and the computing budget. 

The function $LHS(\mathcal{I},N,\rho_m)$ takes the problem instance, total budget and $\rho_m$ as input and returns an initial population of solutions sampled using LHS with size $\frac{N}{1+\rho_m}$. This population is evaluated in LF and partitioned using $Partition(A,k)$. It takes an archive of solutions and a specified number of groups $k$ as inputs, ranks the solutions by objective value and returns $k$ equal-size groups based on their ranks. In \cite{xu2016mo2tos}, $q=10$ was used for the experiments. The remainder of the procedure is similar to Algorithm~\ref{alg:local-ocba}, with $\Delta = 5$ corresponding to the value of $\Delta_2$.