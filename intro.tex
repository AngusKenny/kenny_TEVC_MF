\section{Introduction}
% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.

% \hemant{IEEE requires use of US versions of the spelling ('-ize').}
\IEEEPARstart{M}{any} real-world engineering design problems require estimation of responses that are intractable for exact or analytical methods. In such cases, two alternatives are commonly resorted to: numerical simulations or physical testing of a prototype~\cite{forrester2008engineering}. When used in-loop during design optimization using iterative methods such as evolutionary algorithms~(EAs), both of these methods tend to be prohibitively slow; as well as potentially cost and resource intensive~\cite{jin2009systems}. Such optimization problems where each design evaluation incurs significant cost in any form are referred to as expensive optimization problems.

Simulation-based optimization~(SO) refers to the methods that deal with optimization problems involving  numerical simulations\footnote{For brevity, the discussion is restricted to simulation-based design, but the same principles can be applied to other expensive optimization problems such as those involving physical prototyping.}. Typically, these methods make use of surrogates/approximations, also referred to as metamodels, to reduce the computational expense~\cite{amaran2016simulation}. The basic principle is to use historical information from previously evaluated designs to build a surrogate model of the response landscape. The predicted values from these surrogate models can be then utilized to determine new candidate solutions that are likely to be competent when evaluated using the true~(time consuming) simulation. Through this informed pre-selection, the number of expensive evaluations can be significantly reduced during the course of optimization. 

Some numerical simulation processes allow control over the resolution, or \emph{fidelity}, of the estimated responses. For example, in finite element analysis~(FEA) or computational fluid dynamic~(CFD) simulations, the mesh size can be controlled to yield solutions with different fidelities~\cite{branke2016efficient,toal2015some}. A coarse mesh yields a low-fidelity~(LF) performance estimate that is relatively fast to compute but less accurate, while a fine mesh yields a high-fidelity~(HF) estimate that is relatively more time consuming but more accurate. Multi-fidelity  methods~(MF) are a special class of methods that attempt to efficiently combine the information from different fidelities with the overarching goal of identifying optimal design(s) that are good based on high-fidelity estimates. 

A number of different approaches to MF optimization have been investigated in the literature. Many of these approaches are based on the co-kriging technique described by Forrester et al.~\cite{forrester2007multi} which correlates the two sets of samples, low- and high-fidelity, to produce a single prediction model. This technique is an extension of the autoregressive model first introduced by Kennedy and O'Hagan~\cite{kennedy2000predicting}. The two key aspects in which the different methods in this category deviate from each other is in how they collect these samples and how they search the model for potential candidates for evaluation. Laurenceau and Sagaut~\cite{laurenceau2008building} investigated a number of different sampling methods for use with kriging and co-kriging models and illustrated their performance using an airfoil design problem. Huang et al.~\cite{huang2013research} combined a genetic algorithm with co-kriging to optimize wing-body drag reduction in aerodynamic design. Perdikaris et al.~\cite{perdikaris2015multi} incorporated elements of statistical learning into a co-kriging framework to cross-correlate ensembles of multi-fidelity surrogate models. Yang et al.~\cite{yang2019physics} adopted a physics-informed approach, constructing models based on sparsely observed domain knowledge, representing unknowns as random variables or fields which are regressed using elements of co-kriging. Giraldo et al.~\cite{giraldo2020cokriging} provided an extension to co-kriging for use when the secondary variable is functional, based on the work of Goulard and Voltz~\cite{goulard1993geostatistical}.

Among the approaches that do not use co-kriging models, some of the prominent ones include the following. Lv et al.~\cite{lv2021multi} employed a canonical correlation analysis-based model, in which the least squares method was used to determine the optimal parameters. Ariyarit and Kanazaki~\cite{ariyarit2017multi} used a hybrid method which employed a kriging model to estimate local deviations and a radial basis function to approximate the global model for airfoil design problems. Hebbal et al.~\cite{hebbal2021multi} and Cutajar et al.~\cite{cutajar2019deep} both use machine learning techniques that treat the layers of a deep Gaussian process as different fidelity levels to capture non-linear correlations between various fidelities. Xu et al.~\cite{xu2016mo2tos} propose a two-stage process that uses ordinal transformation to map the original multi-dimensional design space into a one-dimensional ordinal space which is sampled from using a method based on optimal computational budget allocation (OCBA) algorithm proposed by Chen and Lee~\cite{chen2011stochastic}. Branke et al.~\cite{branke2016efficient} and Lim et al.~\cite{lim2008evolutionary} both adopt evolutionary approaches to solving MF problems. Bryson and Rumpfkeil~\cite{bryson2018multifidelity} proposed a versatile quasi-Newton method framework, while Ng and Willcox~\cite{ng2014multifidelity} proposed a number of approaches for multi-fidelity optimization under uncertainty.

The majority of these approaches sample solutions \emph{a priori} and evaluate them in low- and high-fidelity and build models based on these samples and use some global search method to optimize them. To ensure these constructed models are adequately representative, it is important to maintain a diversity of samples across the entire the design space. However, sampling without any prior knowledge can result in spending computational resources in areas which are less promising. Of those which do sample iteratively, information is typically only shared in one direction between the two datasets. Low-fidelity solutions are sampled randomly, or using some independent process, and used to inform where the high-fidelity solutions should be sampled from; but no information is then shared in the reverse direction, to inform the low-fidelity sampling process. Again, this can result in computational resources being consumed inefficiently in regions of the search space which do not yield high quality solutions, especially in high-dimensional problems. 

To overcome these limitations and improve the performance for MF methods, this paper proposes an iterative two-stage, bound-constrained, single-objective multi-fidelity optimisation algorith, referred to here as \AlgName{}. It uses previously obtained information about promising areas of the search space to define a restricted neighbourhood using a guided differential evolution (DE)~\cite{storn1997differential} process based on a kriging model of the low-fidelity samples. This neighbourhood is then sampled from and searched, using a method derived from OCBA, to determine a set of candidates that undergo low-fidelity simulation. The information from these simulations is used to update the low-fidelity model and also a co-kriging-based surrogate model of the high-fidelity samples, which is searched globally using DE to find a suitable candidate for high-fidelity simulation. Finally, these high-fidelity samples are used to update the surrogate model and also to help determine the restricted neighbourhood in the next iteration. By using the high-fidelity simulation information to inform and restrict the region of interest while searching the low-fidelity model, \AlgName{} maintains two-way information sharing between the sets of samples. The performance of the \AlgName{} algorithm is compared against a base-line co-kriging-based MF algorithm on two separate suites of test functions. The first is a common set of multi-fidelity test-functions from the literature, and the second is a set of multi-fidelity test functions that are generated from the standard test functions using the methods described in the paper by Wang et al~\cite{wang2017generic}. In addition to this, some important properties of \AlgName{} are also investigated.

The remainder of this paper is organized as follows. Section~\ref{sec:back} describes the nature of problems studied, along with the background and related work that form some of the key components of \AlgName{}. The algorithm itself is detailed in Section~\ref{sec:method}, describing all of its constituent parts and detailing some similarities and differences with related techniques from the literature. Experimental design and the test suites are discussed in Section~\ref{sec:exp}, with Section~\ref{sec:results} presenting the results of these experiments and a discussion of their implications. Finally, Section~\ref{sec:conc} provides the conclusion and outlines some future directions for potential improvement.
